{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0458d-5150-47ef-aac6-9010b3b76b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import torch\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check GPU availability and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Enhanced Data Loading and Preprocessing\n",
    "def load_and_process_daily_files():\n",
    "    daily_files = [\n",
    "        'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
    "        'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
    "        'Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
    "        'Monday-WorkingHours.pcap_ISCX.csv',\n",
    "        'Thursday-WorkingHours-Afternoon-Infiltration.pcap_ISCX.csv',\n",
    "        'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
    "        'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
    "        'Wednesday-workingHours.pcap_ISCX.csv'\n",
    "    ]\n",
    "    \n",
    "    dfs = []\n",
    "    for file in daily_files:\n",
    "        filepath = os.path.join('CIC-IDS2017', file)\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"Loading {file}...\")\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, low_memory=False)\n",
    "                dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file}\")\n",
    "    \n",
    "    if not dfs:\n",
    "        print(\"No data files found\")\n",
    "        return None\n",
    "    \n",
    "    full_df = pd.concat(dfs, axis=0)\n",
    "    full_df.columns = full_df.columns.str.strip()\n",
    "    full_df = full_df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Enhanced feature selection\n",
    "    cols_to_drop = ['Flow ID', 'Source IP', 'Destination IP', 'Timestamp', 'Fwd Header Length']\n",
    "    cols_to_drop = [col for col in cols_to_drop if col in full_df.columns]\n",
    "    full_df = full_df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    # Handle infinite values and NaNs\n",
    "    numeric_cols = full_df.select_dtypes(include=[np.number]).columns\n",
    "    full_df[numeric_cols] = full_df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    full_df = full_df.dropna()\n",
    "    \n",
    "    # Advanced label encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    full_df['Label'] = label_encoder.fit_transform(full_df['Label'])\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(\"Label mapping:\", label_mapping)\n",
    "    \n",
    "    # Smart class balancing with stratified sampling\n",
    "    rus = RandomUnderSampler(random_state=42, sampling_strategy='not minority')\n",
    "    X_res, y_res = rus.fit_resample(full_df.drop('Label', axis=1), full_df['Label'])\n",
    "    balanced_df = pd.DataFrame(X_res, columns=full_df.drop('Label', axis=1).columns)\n",
    "    balanced_df['Label'] = y_res\n",
    "    \n",
    "    balanced_df.to_csv('CIC-IDS2017/processed_cic_ids2017.csv', index=False)\n",
    "    return balanced_df\n",
    "\n",
    "# 2. Enhanced CyberSecurity Environment with GPU support\n",
    "class CyberSecurityEnv(gym.Env):\n",
    "    def __init__(self, data_path='CIC-IDS2017/processed_cic_ids2017.csv'):\n",
    "        super(CyberSecurityEnv, self).__init__()\n",
    "        \n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        self.labels = self.data['Label'].values\n",
    "        features = self.data.drop('Label', axis=1)\n",
    "        \n",
    "        # Enhanced feature scaling\n",
    "        self.scaler.fit(features)\n",
    "        self.features = self.scaler.transform(features).astype(np.float32)\n",
    "        \n",
    "        # Dynamic action space based on unique labels\n",
    "        self.unique_labels = np.unique(self.labels)\n",
    "        self.action_space = spaces.Discrete(len(self.unique_labels))\n",
    "        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, \n",
    "            high=np.inf, \n",
    "            shape=(self.features.shape[1],), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Adaptive episode length\n",
    "        self.episode_length = min(2000, len(self.data) // 5)\n",
    "        self.current_step = 0\n",
    "        self.start_step = 0\n",
    "        self.attack_history = deque(maxlen=200)\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        max_start = max(1, len(self.data) - self.episode_length)\n",
    "        self.current_step = random.randint(0, max_start)\n",
    "        self.start_step = self.current_step\n",
    "        self.attack_history.clear()\n",
    "        obs = self._next_observation()\n",
    "        return obs, {}\n",
    "        \n",
    "    def _next_observation(self):\n",
    "        return self.features[self.current_step]\n",
    "        \n",
    "    def step(self, action):\n",
    "        label = self.labels[self.current_step]\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {'label': label}\n",
    "        \n",
    "        # Enhanced reward structure\n",
    "        if action == label:\n",
    "            reward = 3.0  # Higher reward for correct classification\n",
    "        else:\n",
    "            if label == 0:  # False positive\n",
    "                reward = -3.0\n",
    "            else:  # False negative or wrong attack type\n",
    "                if action == 0:  # Missed attack completely\n",
    "                    reward = -5.0\n",
    "                else:  # Wrong attack type\n",
    "                    reward = -1.0\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Termination conditions\n",
    "        if self.current_step >= len(self.data) - 1:\n",
    "            done = True\n",
    "        elif self.current_step - self.start_step >= self.episode_length:\n",
    "            done = True\n",
    "            \n",
    "        next_obs = self._next_observation()\n",
    "        return next_obs, reward, done, False, info\n",
    "\n",
    "# 3. GPU-accelerated Training Function\n",
    "def train_agent():\n",
    "    data = load_and_process_daily_files()\n",
    "    if data is None:\n",
    "        print(\"Data processing failed\")\n",
    "        return None\n",
    "    \n",
    "    env = CyberSecurityEnv()\n",
    "    \n",
    "    try:\n",
    "        check_env(env)\n",
    "        print(\"Environment check passed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Environment check failed: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Early stopping callback\n",
    "    callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=500, verbose=1)\n",
    "    eval_callback = EvalCallback(\n",
    "        env,\n",
    "        callback_on_new_best=callback_on_best,\n",
    "        best_model_save_path='./logs/',\n",
    "        log_path='./logs/',\n",
    "        eval_freq=5000,\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Enhanced neural network architecture with GPU support\n",
    "    policy_kwargs = dict(\n",
    "        activation_fn=torch.nn.ReLU,\n",
    "       net_arch=dict(pi=[1024, 512, 256, 128], vf=[1024, 512, 256, 128]),\n",
    "        optimizer_class=torch.optim.AdamW,\n",
    "        optimizer_kwargs=dict(weight_decay=1e-4, eps=1e-5)\n",
    "    )\n",
    "    \n",
    "    # Configure PPO for GPU training\n",
    "    model = PPO(\n",
    "        'MlpPolicy',\n",
    "        env,\n",
    "        device=device,  # Enable GPU acceleration\n",
    "        verbose=2,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        learning_rate=2.5e-4,\n",
    "        n_steps=4096,\n",
    "        batch_size=256,\n",
    "        n_epochs=10,\n",
    "        gamma=0.995,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        clip_range_vf=0.2,\n",
    "        ent_coef=0.01,\n",
    "        max_grad_norm=0.5,\n",
    "        target_kl=0.02,\n",
    "        tensorboard_log=\"./tensorboard_logs/\"\n",
    "    )\n",
    "    \n",
    "    print(\"Starting training with GPU acceleration...\")\n",
    "    model.learn(\n",
    "        total_timesteps=200000,\n",
    "        callback=eval_callback,\n",
    "        tb_log_name=\"ppo_cyber_gpu\",\n",
    "        progress_bar=True\n",
    "    )\n",
    "    \n",
    "    model.save(\"enhanced_cyber_security_ppo_gpu\")\n",
    "    print(\"Training completed and model saved\")\n",
    "    return model\n",
    "\n",
    "# 4. Comprehensive Evaluation Function\n",
    "def evaluate_model(model, num_episodes=20):\n",
    "    env = CyberSecurityEnv()\n",
    "    \n",
    "    results = {\n",
    "        'total_rewards': [],\n",
    "        'confusion_matrix': np.zeros((len(env.unique_labels), len(env.unique_labels))),\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': []\n",
    "    }\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        episode_stats = {\n",
    "            'true_positives': 0,\n",
    "            'false_positives': 0,\n",
    "            'false_negatives': 0,\n",
    "            'total': 0\n",
    "        }\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Update confusion matrix\n",
    "            true_label = info['label']\n",
    "            results['confusion_matrix'][true_label][action] += 1\n",
    "            \n",
    "            # Update episode stats\n",
    "            if action == true_label:\n",
    "                episode_stats['true_positives'] += 1\n",
    "            else:\n",
    "                if true_label == 0:\n",
    "                    episode_stats['false_positives'] += 1\n",
    "                else:\n",
    "                    episode_stats['false_negatives'] += 1\n",
    "            episode_stats['total'] += 1\n",
    "        \n",
    "        results['total_rewards'].append(total_reward)\n",
    "        \n",
    "        # Calculate precision, recall, f1 for this episode\n",
    "        precision = episode_stats['true_positives'] / (episode_stats['true_positives'] + episode_stats['false_positives'] + 1e-6)\n",
    "        recall = episode_stats['true_positives'] / (episode_stats['true_positives'] + episode_stats['false_negatives'] + 1e-6)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        \n",
    "        results['precision'].append(precision)\n",
    "        results['recall'].append(recall)\n",
    "        results['f1'].append(f1)\n",
    "        \n",
    "        print(f\"Episode {ep+1}: Reward={total_reward:.1f}, Precision={precision:.2%}, Recall={recall:.2%}, F1={f1:.2%}\")\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    print(\"\\n=== Final Evaluation Metrics ===\")\n",
    "    print(f\"Average Reward: {np.mean(results['total_rewards']):.2f} ± {np.std(results['total_rewards']):.2f}\")\n",
    "    print(f\"Average Precision: {np.mean(results['precision']):.2%} ± {np.std(results['precision']):.2%}\")\n",
    "    print(f\"Average Recall: {np.mean(results['recall']):.2%} ± {np.std(results['recall']):.2%}\")\n",
    "    print(f\"Average F1 Score: {np.mean(results['f1']):.2%} ± {np.std(results['f1']):.2%}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(results['confusion_matrix'], cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 5. Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Train or load model\n",
    "    try:\n",
    "        model = PPO.load(\"enhanced_cyber_security_ppo_gpu\", device=device)\n",
    "        print(\"Loaded trained model\")\n",
    "    except:\n",
    "        print(\"No saved model found, training new model...\")\n",
    "        model = train_agent()\n",
    "    \n",
    "    # Evaluate model\n",
    "    if model is not None:\n",
    "        results = evaluate_model(model, num_episodes=20)\n",
    "        \n",
    "        # Plot training rewards\n",
    "        if os.path.exists(\"./tensorboard_logs/ppo_cyber_gpu\"):\n",
    "            from stable_baselines3.common.logger import read_csv\n",
    "            try:\n",
    "                log_df = read_csv(\"./tensorboard_logs/ppo_cyber_gpu\")\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.plot(log_df['time/total_timesteps'], log_df['rollout/ep_rew_mean'])\n",
    "                plt.title(\"Training Progress\")\n",
    "                plt.xlabel(\"Timesteps\")\n",
    "                plt.ylabel(\"Average Episode Reward\")\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not plot training progress: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e24443-4d85-45d8-9a5a-36c7293527e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
